{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# Python Standard Library Modules\n",
    "import os\n",
    "import random\n",
    "import pathlib\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# External Libraries\n",
    "from gluonts.dataset import common\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.model import deepar\n",
    "from gluonts.mx.trainer import Trainer\n",
    "from hyperopt import fmin, hp, tpe, STATUS_OK, STATUS_FAIL, Trials\n",
    "from hyperopt.pyll import scope\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "mx.random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "prediction_length = 30\n",
    "# validation_length = 30\n",
    "# if validation_length:\n",
    "#     prediction_length = prediction_length + validation_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIOTECH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TYRA.csv\n",
      "NAUT.csv\n",
      "BBIO.csv\n",
      "VIR.csv\n",
      "JNCE.csv\n",
      "NBIX.csv\n",
      "VRTX.csv\n",
      "LVTX.csv\n",
      "PSTX.csv\n",
      "HARP.csv\n",
      "BCYC.csv\n",
      "CNTA.csv\n",
      "SGMO.csv\n",
      "ITCI.csv\n",
      "KNSA.csv\n",
      "MTEM.csv\n",
      "OLMA.csv\n",
      "SGTX.csv\n",
      "MYOV.csv\n",
      "EDIT.csv\n",
      "NKTX.csv\n",
      "IBRX.csv\n",
      "OMGA.csv\n",
      "REPL.csv\n",
      "PHVS.csv\n",
      "COGT.csv\n",
      "FGEN.csv\n",
      "ERAS.csv\n",
      "RXDX.csv\n",
      "RFL.csv\n",
      "TECH.csv\n",
      "PGEN.csv\n",
      "ABOS.csv\n",
      "RAIN.csv\n",
      "NXTC.csv\n",
      "KRON.csv\n",
      "ANAB.csv\n",
      "DNLI.csv\n",
      "RPRX.csv\n",
      "CYTK.csv\n",
      "OPT.csv\n",
      "FDMT.csv\n",
      "GRTS.csv\n",
      "GRCL.csv\n",
      "RARE.csv\n",
      "SNDX.csv\n",
      "TPTX.csv\n",
      "ERYP.csv\n",
      "ALNY.csv\n",
      "FREQ.csv\n",
      "LYEL.csv\n",
      "KURA.csv\n",
      "GMAB.csv\n",
      "MESO.csv\n",
      "QURE.csv\n",
      "SANA.csv\n",
      "TSHA.csv\n",
      "STOK.csv\n",
      "ADCT.csv\n",
      "MIST.csv\n",
      "PASG.csv\n",
      "ATRA.csv\n",
      "KLDO.csv\n",
      "DCPH.csv\n",
      "ANNX.csv\n",
      "APRE.csv\n",
      "BLU.csv\n",
      "NVAX.csv\n",
      "MDGL.csv\n",
      "SPRB.csv\n",
      "ZYME.csv\n",
      "CABA.csv\n",
      "APLS.csv\n",
      "VERV.csv\n",
      "KDMN.csv\n",
      "MGTX.csv\n",
      "NUVB.csv\n",
      "PCVX.csv\n",
      "BMEA.csv\n",
      "MRVI.csv\n",
      "IPSC.csv\n",
      "PTCT.csv\n",
      "DCAL.BO.csv\n",
      "ALGS.csv\n",
      "SEER.csv\n",
      "DSGN.csv\n",
      "RCUS.csv\n",
      "ENTA.csv\n",
      "PRAX.csv\n",
      "VOR.csv\n",
      "BCEL.csv\n",
      "VIRX.csv\n",
      "DRNA.csv\n",
      "MOR.csv\n",
      "NGM.csv\n",
      "KNTE.csv\n",
      "AKUS.csv\n",
      "ALKS.csv\n",
      "JAZZ.csv\n",
      "PLRX.csv\n",
      "GTHX.csv\n",
      "ABSI.csv\n",
      "ARVN.csv\n",
      "ADPT.csv\n",
      "YMAB.csv\n",
      "PMVP.csv\n",
      "RGNX.csv\n",
      "BMRN.csv\n",
      "TCRR.csv\n",
      "CYT.csv\n",
      "INZY.csv\n",
      "GOSS.csv\n",
      "DAWN.csv\n",
      "PRVB.csv\n",
      "FIXX.csv\n",
      "FUSN.csv\n",
      "RPTX.csv\n",
      "INCY.csv\n",
      "TARS.csv\n",
      "CRNX.csv\n",
      "GLUE.csv\n",
      "CCXI.csv\n",
      "BNTX.csv\n",
      "KZR.csv\n",
      "ICPT.csv\n",
      "CCCC.csv\n",
      "OYST.csv\n",
      "TNYA.csv\n",
      "GBT.csv\n",
      "ARWR.csv\n",
      "CALT.csv\n",
      "ANGN.csv\n",
      "INO.csv\n",
      "SQZ.csv\n",
      "IPHA.csv\n",
      "BCRX.csv\n",
      "NBTX.csv\n",
      "AMAM.csv\n",
      "SGEN.csv\n",
      "BLUE.csv\n",
      "RVMD.csv\n",
      "LEGN.csv\n",
      "TERN.csv\n",
      "CRTX.csv\n",
      "CRBU.csv\n",
      "HOWL.csv\n",
      "EXEL.csv\n",
      "SCPH.csv\n",
      "INVA.csv\n",
      "HOOK.csv\n",
      "BHVN.csv\n",
      "SRRK.csv\n",
      "SRPT.csv\n",
      "SWTX.csv\n",
      "IDYA.csv\n",
      "ARNA.csv\n",
      "PRLD.csv\n",
      "EWTX.csv\n",
      "IMGN.csv\n",
      "MRTX.csv\n",
      "BDTX.csv\n",
      "NUVL.csv\n",
      "MRNA.csv\n",
      "ACAD.csv\n",
      "MGNX.csv\n",
      "IMGO.csv\n",
      "MOLN.csv\n",
      "ALEC.csv\n",
      "SYNGENE.BO.csv\n",
      "PRTA.csv\n",
      "HALO.csv\n",
      "KDNY.csv\n",
      "BIOCON.BO.csv\n",
      "AMTI.csv\n",
      "SPRO.csv\n",
      "AGIO.csv\n",
      "AUTL.csv\n",
      "KPTI.csv\n",
      "RLMD.csv\n",
      "REGN.csv\n",
      "MRSN.csv\n",
      "GLPG.csv\n",
      "NKTR.csv\n",
      "DNA.csv\n",
      "ASND.csv\n",
      "XBIT.csv\n",
      "AVRO.csv\n",
      "ADAP.csv\n",
      "VECT.csv\n",
      "AVIR.csv\n",
      "CERT.csv\n",
      "INSM.csv\n",
      "IMUX.csv\n",
      "IMVT.csv\n",
      "ALLK.csv\n",
      "BGNE.csv\n",
      "NVO.csv\n",
      "HUMA.csv\n",
      "ALVR.csv\n",
      "MCRB.csv\n",
      "EVLO.csv\n",
      "ACHL.csv\n",
      "RLYB.csv\n",
      "ATHA.csv\n",
      "TIL.csv\n",
      "DBTX.csv\n",
      "ALXO.csv\n",
      "ELEV.csv\n",
      "ISEE.csv\n",
      "ICVX.csv\n",
      "IONS.csv\n",
      "PBYI.csv\n",
      "ZEAL.csv\n",
      "BLI.csv\n",
      "DTIL.csv\n",
      "ORIC.csv\n",
      "BEAM.csv\n",
      "RXRX.csv\n",
      "UTHR.csv\n",
      "IMCR.csv\n",
      "HCM.csv\n",
      "DYN.csv\n",
      "IGMS.csv\n",
      "STTK.csv\n",
      "RUBY.csv\n",
      "VALN.csv\n",
      "AKRO.csv\n",
      "ALLO.csv\n",
      "ABCM.csv\n",
      "CDXS.csv\n",
      "ARQT.csv\n",
      "GBIO.csv\n",
      "ACRS.csv\n",
      "PHAT.csv\n",
      "BOLT.csv\n",
      "CGEM.csv\n",
      "FNCH.csv\n",
      "BPMC.csv\n",
      "ABCL.csv\n",
      "ARGX.csv\n"
     ]
    }
   ],
   "source": [
    "gluon_list = []\n",
    "def covert_yahoo_series_dir(path: str, prediction_length: int, gluon_list=None) -> list:\n",
    "    \"\"\"Clean and load all biotech histories in the Yahoo biotech folder\n",
    "\n",
    "    Params:\n",
    "        path: folder full of historical crypto coins timeseries data\n",
    "        prediction_length: length on which to predict\n",
    "    Returns:\n",
    "        List of Gluon-compatible dicts from the coin data\n",
    "    \"\"\"\n",
    "    if gluon_list is not None:\n",
    "        print(\"NOT NONE\")\n",
    "        gluon_list = gluon_list\n",
    "    else:\n",
    "        gluon_list = []\n",
    "    for file in os.listdir(path):\n",
    "        print(file)\n",
    "        stock_gluon_dict = dict()\n",
    "        file_path = path + file\n",
    "        stock = pd.read_csv(file_path)\n",
    "        stock[\"Date\"] = pd.to_datetime(stock[\"Date\"])\n",
    "        stock.set_index(\"Date\", inplace=True)\n",
    "        if len(stock) < 100:\n",
    "            continue\n",
    "        total_na_vals = stock.isna().sum()[0]\n",
    "#         print(f\"TOTAL NAs BEFORE ASFREQ B for {file} is {total_na_vals}\")\n",
    "        stock = stock.asfreq(\"B\")\n",
    "        total_na_vals = stock.isna().sum()[0]\n",
    "#         print(f\"TOTAL NAs for {file} is {total_na_vals}\")\n",
    "        if (total_na_vals / len(stock)) > 0.25:\n",
    "            print(f\"CONTINUED {file}\")\n",
    "            continue\n",
    "        # Get values for ListDatasets\n",
    "        stock_closes = stock[\"Close\"]\n",
    "        stock_closes.index = pd.DatetimeIndex(stock_closes.index)\n",
    "#         stock_closes.dropna(inplace=True)\n",
    "#         coin_closes.fillna(method='bfill', inplace=True)\n",
    "#         coin_closes.dropna(inplace=True)\n",
    "        stock_closes = stock_closes.asfreq(\"B\")\n",
    "#         stock_closes.dropna(inplace=True)\n",
    "        start = stock_closes.index[0]\n",
    "#         stock_closes = stock_closes.reset_index()\n",
    "\n",
    "        stock_gluon_dict[\"test\"] = {\n",
    "            \"start\": start,\n",
    "            \"target\": stock_closes,\n",
    "            \"name\": file,\n",
    "        }\n",
    "\n",
    "        stock_gluon_dict[\"train\"] = {\n",
    "            \"start\": start,\n",
    "            \"target\": stock_closes[:-prediction_length],\n",
    "            \"name\": file,\n",
    "        }\n",
    "\n",
    "        gluon_list.append(stock_gluon_dict)\n",
    "\n",
    "    return gluon_list\n",
    "\n",
    "\n",
    "gluon_list = covert_yahoo_series_dir(\"../data/historical_yahoo_biotech/\", prediction_length=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT NONE\n",
      "ZG.csv\n",
      "MSFT (1).csv\n",
      "INTC.csv\n",
      "PYPL.csv\n",
      "ATVI.csv\n",
      "EA.csv\n",
      "AMD.csv\n",
      "MTCH.csv\n",
      "NVDA.csv\n",
      "FB.csv\n",
      "TTD.csv\n",
      "AAPL (1).csv\n",
      "TSLA.csv\n",
      "AMZN (1).csv\n",
      "YELP.csv\n",
      "GOOG (1).csv\n",
      "BABA.csv\n",
      "CRM.csv\n"
     ]
    }
   ],
   "source": [
    "gluon_list = covert_yahoo_series_dir(\"/Users/dan/projects/gluon/data/historical_yahoo_tech_big_movers/\", prediction_length=30, gluon_list=gluon_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"always\")\n",
    "\n",
    "import mxnet as mx\n",
    "mx.random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "test_data = common.ListDataset(\n",
    "    [\n",
    "    ],\n",
    "    freq=\"B\",\n",
    ")\n",
    "\n",
    "train_data = common.ListDataset(\n",
    "    [\n",
    "    ],\n",
    "    freq=\"B\",\n",
    ")\n",
    "\n",
    "for stock_gluon_dict in gluon_list:\n",
    "    test_data.list_data.append(stock_gluon_dict['test'])\n",
    "    train_data.list_data.append(stock_gluon_dict['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data.list_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dan/opt/anaconda3/lib/python3.7/site-packages/gluonts/core/component.py:345: DeprecationWarning: batch_size argument is deprecated\n",
      "  return init(self, **all_args)\n",
      "/Users/dan/opt/anaconda3/lib/python3.7/site-packages/gluonts/mx/trainer/_base.py:158: DeprecationWarning: Trainer argument \"learning_rate_decay_factor\" is deprecated. Use callbacks instead.\n",
      "  DeprecationWarning,\n",
      "/Users/dan/opt/anaconda3/lib/python3.7/site-packages/gluonts/mx/trainer/_base.py:166: DeprecationWarning: Trainer argument \"patience\" is deprecated. Use callbacks instead.\n",
      "  DeprecationWarning,\n",
      "/Users/dan/opt/anaconda3/lib/python3.7/site-packages/gluonts/mx/trainer/_base.py:172: DeprecationWarning: Trainer argument \"minimum_learning_rate\" is deprecated. Use callbacks instead.\n",
      "  DeprecationWarning,\n",
      "100%|██████████| 50/50 [00:03<00:00, 15.12it/s, epoch=1/50, avg_epoch_loss=4.06]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.06it/s, epoch=2/50, avg_epoch_loss=3.33]\n",
      "100%|██████████| 50/50 [00:03<00:00, 15.93it/s, epoch=3/50, avg_epoch_loss=2.53]\n",
      "100%|██████████| 50/50 [00:03<00:00, 15.94it/s, epoch=4/50, avg_epoch_loss=2.3]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.09it/s, epoch=5/50, avg_epoch_loss=2.2]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.04it/s, epoch=6/50, avg_epoch_loss=2.18]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.14it/s, epoch=7/50, avg_epoch_loss=2.04]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.23it/s, epoch=8/50, avg_epoch_loss=2.05]\n",
      "100%|██████████| 50/50 [00:03<00:00, 15.84it/s, epoch=9/50, avg_epoch_loss=2.08]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.21it/s, epoch=10/50, avg_epoch_loss=2.03]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.20it/s, epoch=11/50, avg_epoch_loss=2.11]\n",
      "100%|██████████| 50/50 [00:03<00:00, 15.47it/s, epoch=12/50, avg_epoch_loss=2.05]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.00it/s, epoch=13/50, avg_epoch_loss=2.06]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.07it/s, epoch=14/50, avg_epoch_loss=2.07]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.01it/s, epoch=15/50, avg_epoch_loss=2.1]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.10it/s, epoch=16/50, avg_epoch_loss=1.97]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.13it/s, epoch=17/50, avg_epoch_loss=1.97]\n",
      "100%|██████████| 50/50 [00:03<00:00, 15.92it/s, epoch=18/50, avg_epoch_loss=2.07]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.16it/s, epoch=19/50, avg_epoch_loss=2.02]\n",
      "100%|██████████| 50/50 [00:03<00:00, 15.40it/s, epoch=20/50, avg_epoch_loss=1.92]\n",
      "100%|██████████| 50/50 [00:03<00:00, 15.86it/s, epoch=21/50, avg_epoch_loss=2.02]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.15it/s, epoch=22/50, avg_epoch_loss=1.98]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.10it/s, epoch=23/50, avg_epoch_loss=1.95]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.11it/s, epoch=24/50, avg_epoch_loss=2.05]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.03it/s, epoch=25/50, avg_epoch_loss=1.93]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.14it/s, epoch=26/50, avg_epoch_loss=2]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.18it/s, epoch=27/50, avg_epoch_loss=1.96]\n",
      "100%|██████████| 50/50 [00:03<00:00, 15.96it/s, epoch=28/50, avg_epoch_loss=1.96]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.25it/s, epoch=29/50, avg_epoch_loss=1.97]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.16it/s, epoch=30/50, avg_epoch_loss=1.9]\n",
      "100%|██████████| 50/50 [00:03<00:00, 15.24it/s, epoch=31/50, avg_epoch_loss=1.96]\n",
      "100%|██████████| 50/50 [00:03<00:00, 15.51it/s, epoch=32/50, avg_epoch_loss=1.97]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.01it/s, epoch=33/50, avg_epoch_loss=1.93]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.05it/s, epoch=34/50, avg_epoch_loss=1.86]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.19it/s, epoch=35/50, avg_epoch_loss=1.91]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.09it/s, epoch=36/50, avg_epoch_loss=1.88]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.01it/s, epoch=37/50, avg_epoch_loss=1.92]\n",
      "100%|██████████| 50/50 [00:03<00:00, 15.93it/s, epoch=38/50, avg_epoch_loss=1.88]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.10it/s, epoch=39/50, avg_epoch_loss=1.95]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.08it/s, epoch=40/50, avg_epoch_loss=1.89]\n",
      "100%|██████████| 50/50 [00:03<00:00, 15.93it/s, epoch=41/50, avg_epoch_loss=1.84]\n",
      "100%|██████████| 50/50 [00:03<00:00, 15.98it/s, epoch=42/50, avg_epoch_loss=1.82]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.14it/s, epoch=43/50, avg_epoch_loss=1.86]\n",
      "100%|██████████| 50/50 [00:03<00:00, 15.95it/s, epoch=44/50, avg_epoch_loss=1.86]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.13it/s, epoch=45/50, avg_epoch_loss=1.83]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.07it/s, epoch=46/50, avg_epoch_loss=1.86]\n",
      "100%|██████████| 50/50 [00:03<00:00, 15.90it/s, epoch=47/50, avg_epoch_loss=1.88]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.01it/s, epoch=48/50, avg_epoch_loss=1.86]\n",
      "100%|██████████| 50/50 [00:03<00:00, 16.04it/s, epoch=49/50, avg_epoch_loss=1.87]\n",
      "100%|██████████| 50/50 [00:03<00:00, 15.68it/s, epoch=50/50, avg_epoch_loss=1.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_loss is 145.4655384213718\n",
      "average global_loss is 0.6163794000905585\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(epochs=50, batch_size=256, learning_rate=0.0001)\n",
    "estimator = deepar.DeepAREstimator(\n",
    "        freq=\"B\", \n",
    "#         num_cells=150,\n",
    "#         num_layers=3,\n",
    "        prediction_length=prediction_length, \n",
    "        trainer=trainer,\n",
    "    )\n",
    "\n",
    "predictor = estimator.train(\n",
    "    training_data=train_data,\n",
    ")\n",
    "\n",
    "random.seed(0)\n",
    "mx.random.seed(0)\n",
    "np.random.seed(0)\n",
    "global_loss = 0\n",
    "predictions = predictor.predict(train_data.list_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for index, value in enumerate(range(len(gluon_list))):\n",
    "    prediction = next(predictions)\n",
    "    name = test_data.list_data[index]['name']\n",
    "    full_actual = test_data.list_data[index]['target']\n",
    "    full_actual.dropna(inplace=True)\n",
    "    actual = full_actual[-30:]\n",
    "    preds = pd.Series(prediction.mean)\n",
    "    preds.index = actual.index\n",
    "#     mse = mean_squared_error(actual, preds)\n",
    "    \n",
    "    # PLOT ALL BIOTECH PREDICTIONS\n",
    "#     plt.figure()\n",
    "#     preds.plot(legend=True, label=f\"{name} PREDICTED\")\n",
    "#     actual.plot(legend=True, label=f\"{name} ACTUAL\")\n",
    "#     plt.show()\n",
    "\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_actual = np.array(actual)\n",
    "    scaler.fit([scaled_actual])\n",
    "    scaled_actual = scaler.fit_transform(np.array(scaled_actual[:, np.newaxis]))\n",
    "    scaled_preds = scaler.transform([preds])\n",
    "    scaled_preds = scaled_preds.reshape(-1, 1)\n",
    "    mse = mean_squared_error(scaled_actual, scaled_preds)\n",
    "#     print(f\"mse: {mse}\")\n",
    "    global_loss += mse\n",
    "    \n",
    "print(f\"global_loss is {global_loss}\")\n",
    "print(f\"average global_loss is {global_loss / len(gluon_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-201-02862b3e764e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-201-02862b3e764e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    average global_loss is 1.2ish               # 18\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "average global_loss is 1.2ish               # 18\n",
    "average global_loss is 0.8193485594635367   # 36\n",
    "average global_loss is 1.0578433766058088   # 54\n",
    "average global_loss is 1.0184960608247695   # 69\n",
    "average global_loss is 1.0639288802030842   # 86\n",
    "average global_loss is 0.9494059324316426   # 204\n",
    "average global_loss is 0.8880175967582968   # 241\n",
    "average global_loss is 1.9637798520177      # 276 different exchange\n",
    "average global_loss is 0.9105032333595303   # 240 attempted restore\n",
    "average global_loss is 0.9554277347125465   # 258 w/ big tech movers\n",
    "average global_loss is 0.335191223822778   # 258 w/ big tech movers 10 epochs\n",
    "average global_loss is 0.6163794000905585   # 258 w/ big tech movers 50 epochs\n",
    "average global_loss is 0.4051840267830506   # 258 wo/ big tech movers 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
